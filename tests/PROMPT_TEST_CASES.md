# Prompt para Crear Test Cases Automatizados - Proyecto AMMS

## ğŸ“‹ Instrucciones Generales

Crear un test case automatizado siguiendo exactamente el formato y estructura del archivo de referencia: `C:\Users\Nico\Documents\Proyecto Integrador\amms\tests\test_IT_GUSU_006_RF-074\test_IT_GUSU_006_RF-074.py`

## ğŸ—ï¸ Estructura de Carpetas y Archivos

### Nomenclatura de Carpeta:
```
test_IT_{MODULO}_{NUMERO}_{REQUERIMIENTO}/
```
**Ejemplo:** `test_IT_GUSU_006_RF-074/`

### Nomenclatura de Archivo Principal:
```
test_IT_{MODULO}_{NUMERO}_{REQUERIMIENTO}.py
```
**Ejemplo:** `test_IT_GUSU_006_RF-074.py`

### Archivos Obligatorios en la Carpeta:
1. `test_IT_{MODULO}_{NUMERO}_{REQUERIMIENTO}.py` - Archivo principal
2. `README.md` - DocumentaciÃ³n especÃ­fica del caso
3. `.env.example` - Plantilla de configuraciÃ³n

## ğŸ“ Datos de Entrada Requeridos

Proporcionar SIEMPRE esta informaciÃ³n completa:

```json
{
  "test_info": {
    "id": "IT-XXXX-XXX",
    "titulo": "DescripciÃ³n del caso",
    "modulo": "XXXX",
    "requerimientos": ["RF-XXX", "RF-XXX"],
    "descripcion": "DescripciÃ³n completa del comportamiento a verificar"
  },
  "precondiciones": [
    "â€¢ CondiciÃ³n 1",
    "â€¢ CondiciÃ³n 2", 
    "â€¢ CondiciÃ³n N"
  ],
  "datos_entrada": {
    "datos_validos": {
      "campo1": "valor1",
      "campo2": "valor2"
    },
    "casos_error": {
      "campo_invalido": "valor_invalido",
      "otro_campo_invalido": "otro_valor_invalido"
    }
  },
  "pasos_aat": {
    "arrange": "DescripciÃ³n de preparaciÃ³n",
    "act": [
      "1. Paso 1",
      "2. Paso 2",
      "N. Paso N"
    ],
    "assert": "DescripciÃ³n de verificaciones esperadas"
  },
  "resultado_esperado": [
    "â€¢ Resultado 1",
    "â€¢ Resultado 2",
    "â€¢ Resultado N"
  ]
}
```

## ğŸ”§ ConfiguraciÃ³n de .env

SIEMPRE incluir estas variables en el .env del proyecto raÃ­z:

```env
# Credenciales de login
EMAIL=sigma.inmero@gmail.com
PASSWORD=Admin123456.
HEADLESS=False

# PostgreSQL Database Configuration
DB_HOST=158.69.200.27
DB_PORT=5436
DB_NAME=tester
DB_USER=tester
DB_PASSWORD=sigma.test.2025
```

## ğŸ¯ Estructura del CÃ³digo Principal

### 1. Imports y ConfiguraciÃ³n
Copiar EXACTAMENTE los imports del archivo de referencia, incluyendo:
- `psycopg2` para PostgreSQL
- `selenium` completo
- `faker` para datos de prueba
- `dotenv` para variables de entorno

### 2. Clase DatabaseManager
Copiar COMPLETA la clase `DatabaseManager` del archivo de referencia para:
- ConexiÃ³n a PostgreSQL
- VerificaciÃ³n de datos actualizados
- Log de auditorÃ­a

### 3. Clase Principal del Test
Estructura obligatoria:
```python
class {ModuloTest}:
    def __init__(self, headless: bool = False, iterations: int = 3, verify_db: bool = True):
        # ConfiguraciÃ³n bÃ¡sica
        # Datos del caso de prueba especÃ­fico
        # MÃ©tricas de resultados

    def verify_preconditions(self) -> bool:
        # Verificar BD, ChromeDriver, credenciales

    def setup_driver(self) -> bool:
        # ConfiguraciÃ³n Chrome (headless/visual)

    def login(self) -> bool:
        # Login usando LoginFlow

    def navigate_to_{seccion}(self) -> bool:
        # NavegaciÃ³n especÃ­fica

    def verify_interface_elements(self) -> bool:
        # Verificar elementos clave de la interfaz

    def generate_test_data(self) -> Dict[str, str]:
        # Usar datos del caso de prueba + Faker

    def {accion_principal}(self, test_data: Dict[str, str]) -> bool:
        # AcciÃ³n principal a probar

    def test_field_validations(self, test_data: Dict[str, str]) -> bool:
        # IMPORTANTE: Probar validaciones con datos invÃ¡lidos
        # REPORTAR validaciones fallidas como BUGS

    def save_changes(self, test_data: Dict[str, str]) -> bool:
        # Guardar cambios Y verificar en BD

    def run_single_iteration(self, iteration_num: int) -> bool:
        # Ejecutar secuencia completa de tests

    def run_test(self) -> bool:
        # MÃ©todo principal con verificaciÃ³n de precondiciones

    def _print_final_results(self, successful_iterations: int):
        # Reporte detallado + BUGS ENCONTRADOS

    def cleanup(self):
        # Cerrar navegador y BD
```

## ğŸš¨ REPORTE DE BUGS OBLIGATORIO

### En el mÃ©todo `test_field_validations`:
```python
def test_field_validations(self, test_data: Dict[str, str]) -> bool:
    try:
        print("ğŸ§ª Probando validaciones...")
        
        bugs_found = []
        
        # Por cada validaciÃ³n que falle:
        if not validation_found:
            bug_info = {
                'campo': 'nombre_campo',
                'valor_invalido': test_data['campo_invalido'],
                'descripcion': 'ValidaciÃ³n no muestra error con dato invÃ¡lido',
                'impacto': 'Usuario puede introducir datos incorrectos'
            }
            bugs_found.append(bug_info)
            self.results['bugs_found'].append(bug_info)
            print(f"   ğŸ› BUG DETECTADO: {bug_info['descripcion']}")
```

### En `_print_final_results`:
```python
# Agregar secciÃ³n de BUGS
if self.results['bugs_found']:
    print(f"\nğŸ› BUGS DETECTADOS ({len(self.results['bugs_found'])}):")
    for i, bug in enumerate(self.results['bugs_found'], 1):
        print(f"  {i}. CAMPO: {bug['campo']}")
        print(f"     DATO: {bug['valor_invalido']}")
        print(f"     PROBLEMA: {bug['descripcion']}")
        print(f"     IMPACTO: {bug['impacto']}")
        print()
```

## ğŸ“Š MÃ©tricas de Resultados Obligatorias

```python
self.results = {
    'test_name': 'IT-XXXX (RF-XXX) - TÃ­tulo del test',
    'test_id': 'IT-XXXX',
    'requirements': ['RF-XXX'],
    'iterations_completed': 0,
    'successful_operations': 0,
    'failed_operations': 0,
    'validations_passed': 0,
    'validations_failed': 0,
    'db_verifications': 0,
    'db_verification_failures': 0,
    'bugs_found': [],  # â† NUEVO: Lista de bugs detectados
    'errors_encountered': [],
    'preconditions_met': False,
    'audit_logged': False
}
```

## ğŸš€ CLI Obligatoria

```python
def main():
    parser = argparse.ArgumentParser(
        description='Test IT-XXXX (RF-XXX): DescripciÃ³n',
        epilog="""
Ejemplos de uso:
  python test_IT_XXXX_RF-XXX.py                      # Modo visual con BD
  python test_IT_XXXX_RF-XXX.py --headless           # Modo headless con BD
  python test_IT_XXXX_RF-XXX.py --no-verify-db       # Sin verificaciÃ³n BD
  python test_IT_XXXX_RF-XXX.py --check-env          # Solo verificar configuraciÃ³n
        """
    )
    
    # Argumentos estÃ¡ndar:
    # --headless, --iterations, --no-verify-db, --check-env
```

## ğŸ“– README.md Obligatorio

Estructura del README:
1. **TÃ­tulo con ID y requerimientos**
2. **DescripciÃ³n del caso de prueba**
3. **Precondiciones especÃ­ficas**
4. **Datos de entrada del caso**
5. **ConfiguraciÃ³n tÃ©cnica**
6. **Ejemplos de uso**
7. **InterpretaciÃ³n de resultados**
8. **Reporte de bugs**

## âœ… Verificaciones Finales

Antes de entregar, SIEMPRE verificar:

1. **Estructura de carpetas** correcta
2. **Nomenclatura** siguiendo el formato
3. **ConexiÃ³n BD** funcionando
4. **Test en modo headless** y visual
5. **Reporte de bugs** implementado
6. **DocumentaciÃ³n** completa
7. **Variables de entorno** configuradas

## ğŸ¯ Ejemplo de EjecuciÃ³n

```bash
# Verificar configuraciÃ³n
python test_IT_XXXX_RF-XXX.py --check-env

# Ejecutar con BD
python test_IT_XXXX_RF-XXX.py --headless --iterations 1

# Ejecutar sin BD  
python test_IT_XXXX_RF-XXX.py --headless --no-verify-db

# Modo desarrollo
python test_IT_XXXX_RF-XXX.py --iterations 1
```

## ğŸ“‹ Salida Esperada

```
ğŸ“Š RESULTADOS FINALES - IT-XXXX
ğŸ“‹ IT-XXXX (RF-XXX) - TÃ­tulo del test
ğŸ”— Requerimientos: RF-XXX
================================================================================
âš¡ Operaciones exitosas: X
ğŸ” Verificaciones BD exitosas: X
ğŸ“ Log de auditorÃ­a: âœ… Registrado
ğŸ”§ Precondiciones: âœ… Cumplidas

ğŸ› BUGS DETECTADOS (X):
  1. CAMPO: campo_telefono
     DATO: 123-abc-xyz
     PROBLEMA: ValidaciÃ³n no muestra error con dato invÃ¡lido
     IMPACTO: Usuario puede introducir datos incorrectos

ğŸ“ˆ TASA DE Ã‰XITO: X.X%
ğŸ‰ RESULTADO: TEST EXITOSO
```

---

**USAR ESTE PROMPT COMPLETO** para todos los test cases futuros, referenciando siempre el archivo `test_IT_GUSU_006_RF-074.py` como modelo base y manteniendo la consistencia en estructura, nomenclatura y funcionalidad.
